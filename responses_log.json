{"response": "Multiplying Matrices Without Multiplying\nE.7. Caltech101\nWe only extracted valid windows\u2014i.e., never past the edge\nof an image. We extracted the windows in CHW order,\nmeaning that scalars from the same color channel were\nplaced at contiguous indices. The \u201c\ufb01rst\u201d images are based\non \ufb01lename in lexicographic order.\nWe used pairs of \ufb01lters because using a single \ufb01lter would\nmean timing a matrix-vector product instead of a matrix-\nmatrix product.\nTo allow meaningful speed comparisons across images, we\nresized and center-cropped each image to 224 \u00d7 224 as\ncommonly done in image classi\ufb01cation pipelines (He et al.,\n2016a;b; Huang et al., 2017). We then extracted sliding\nwindows of the appropriate size and used each (\ufb02attened)\nwindow as one row of \u02dc\nA or A. We similarly \ufb02attened the\n\ufb01lters, with each set of coef\ufb01cients forming one column of\nB. In both cases, B has two columns\u2014this is because us-\ning a single \ufb01lter would mean timing a matrix-vector prod-\nuct instead of a matrix-matrix product. Two columns also\nmade sense since Sobel \ufb01lters are often used in horizon-\ntal and vertical pairings, and Gaussian \ufb01lters are often used\ntogether to perform difference-of-Gaussians transforms.\nEven though the RGB values at each position are naturally\nunsigned 8-bit integers, we allowed all rival methods to\noperate on them as 32-bit \ufb02oating point, without includ-\ning the conversion when timing them.\nBecause it only\nrequires checking whether values are above a threshold,\nMADDNESS can operate on 8-bit data directly.\nE.8. Why Not Speed Up Whole Neural Nets?\nUsing our ideas to accelerate overall neural networks and\nother layer types would be a valuable contribution. In fact,\nwe are actively working on this problem. However, as we\nstate in the introduction and problem statement, our focus\nin this paper is approximate matrix multiplication (AMM)\nand we deliberately make no claim about accelerating en-\ntire neural networks or convolutional layers. We limit our\nscope in this way for several reasons:\n1. Approximate matrix multiplication is an established re-\nsearch problem of general interest independent of deep\nlearning.\n2. Lifting a method from accelerating a single layer to an\noverall network is challenging. Just as scalar quantiza-\ntion of network parameters is simple for a single layer\nbut an active area of research for an entire network, so\ntoo is using our method on multiple layers at once an\nopen research problem.\nFor example, it is not clear\nhow to deal with the fact that distributions of activations\nchange throughout training, or how to ef\ufb01ciently incor-\nporate our non-differentiable hash function. We could\nshow how to accelerate one internal FC layer in a net-\nwork, but we don\u2019t want to risk misleading the reader\u2014it\nwould be unclear what conclusions to draw from such re-\nsults, particularly given the dif\ufb01culty of retraining / \ufb01ne-\ntuning without introducing many lurking variables (c.f.,\n(Blalock et al., 2020)).\n3. It is correct that convolution can be reduced to GEMM\nusing im2col, and that accelerating convolution using\nour ideas would be a valuable contribution. However,\nstate-of-the-art algorithms for convolution exploit struc-\nture that is not available to general matrix multiply algo-\nrithms. To match the performance of specialized Wino-\ngrad, direct, FFT-based, and hybrid convolution schemes\nthat do exploit this additional structure, we would have\nto make modi\ufb01cations to our approach that would make\nit less general. For example, the individual spatial po-\nsitions should be encoded only once, and then reused at\nmultiple \ufb01lter positions. Regarding Section 5.5: while\nwe do test our method on matrices of \ufb02attened image\npatches, we do not claim that the overall pipeline of\n\ufb02attening + matrix multiply constitutes a state-of-the-\nart convolution method\u2014we only claim that using our\nmethod in this pipeline outperforms using other AMM\nmethods there.\nIn short, while we believe that our ideas show great promise\nfor accelerating full neural networks and more layer types,\nmaking this happen requires much more research.\nE.9. Additional Results\nIn Section 5, we showed the classi\ufb01cation accuracy as a\nfunction of wall time for the CIFAR-10 and CIFAR-100\nsoftmax classi\ufb01ers, as well as on the UCR datasets.\nIn\nFigure 8 and Figure 9, we instead show normalized mean\nsquared error versus time. In Figure 10 and Figure 11, we\nshow accuracy or NMSE versus number of operations per-\nformed, where one operation is either one multiply-add or\none table lookup, depending on the method. The \ufb01rst two\n\ufb01gures illustrate that NMSE is closely related to classi\ufb01-\ncation accuracy, but with imperfect NMSE still yielding\nexcellent accuracy in many cases.\nThe second two \ufb01g-\nures show that our method\u2019s superior results are not merely\ncaused by the use of faster CPU instructions, but also by\nthe use of fewer basic operations at the algorithm level.\n", "type": "paragraph", "source": "extract all headings", "confidence": 0.057343777269124985, "timestamp": 1753419060.2092466}
{"response": "Multiplying Matrices Without Multiplying\nE.7. Caltech101\nWe only extracted valid windows\u2014i.e., never past the edge\nof an image. We extracted the windows in CHW order,\nmeaning that scalars from the same color channel were\nplaced at contiguous indices. The \u201c\ufb01rst\u201d images are based\non \ufb01lename in lexicographic order.\nWe used pairs of \ufb01lters because using a single \ufb01lter would\nmean timing a matrix-vector product instead of a matrix-\nmatrix product.\nTo allow meaningful speed comparisons across images, we\nresized and center-cropped each image to 224 \u00d7 224 as\ncommonly done in image classi\ufb01cation pipelines (He et al.,\n2016a;b; Huang et al., 2017). We then extracted sliding\nwindows of the appropriate size and used each (\ufb02attened)\nwindow as one row of \u02dc\nA or A. We similarly \ufb02attened the\n\ufb01lters, with each set of coef\ufb01cients forming one column of\nB. In both cases, B has two columns\u2014this is because us-\ning a single \ufb01lter would mean timing a matrix-vector prod-\nuct instead of a matrix-matrix product. Two columns also\nmade sense since Sobel \ufb01lters are often used in horizon-\ntal and vertical pairings, and Gaussian \ufb01lters are often used\ntogether to perform difference-of-Gaussians transforms.\nEven though the RGB values at each position are naturally\nunsigned 8-bit integers, we allowed all rival methods to\noperate on them as 32-bit \ufb02oating point, without includ-\ning the conversion when timing them.\nBecause it only\nrequires checking whether values are above a threshold,\nMADDNESS can operate on 8-bit data directly.\nE.8. Why Not Speed Up Whole Neural Nets?\nUsing our ideas to accelerate overall neural networks and\nother layer types would be a valuable contribution. In fact,\nwe are actively working on this problem. However, as we\nstate in the introduction and problem statement, our focus\nin this paper is approximate matrix multiplication (AMM)\nand we deliberately make no claim about accelerating en-\ntire neural networks or convolutional layers. We limit our\nscope in this way for several reasons:\n1. Approximate matrix multiplication is an established re-\nsearch problem of general interest independent of deep\nlearning.\n2. Lifting a method from accelerating a single layer to an\noverall network is challenging. Just as scalar quantiza-\ntion of network parameters is simple for a single layer\nbut an active area of research for an entire network, so\ntoo is using our method on multiple layers at once an\nopen research problem.\nFor example, it is not clear\nhow to deal with the fact that distributions of activations\nchange throughout training, or how to ef\ufb01ciently incor-\nporate our non-differentiable hash function. We could\nshow how to accelerate one internal FC layer in a net-\nwork, but we don\u2019t want to risk misleading the reader\u2014it\nwould be unclear what conclusions to draw from such re-\nsults, particularly given the dif\ufb01culty of retraining / \ufb01ne-\ntuning without introducing many lurking variables (c.f.,\n(Blalock et al., 2020)).\n3. It is correct that convolution can be reduced to GEMM\nusing im2col, and that accelerating convolution using\nour ideas would be a valuable contribution. However,\nstate-of-the-art algorithms for convolution exploit struc-\nture that is not available to general matrix multiply algo-\nrithms. To match the performance of specialized Wino-\ngrad, direct, FFT-based, and hybrid convolution schemes\nthat do exploit this additional structure, we would have\nto make modi\ufb01cations to our approach that would make\nit less general. For example, the individual spatial po-\nsitions should be encoded only once, and then reused at\nmultiple \ufb01lter positions. Regarding Section 5.5: while\nwe do test our method on matrices of \ufb02attened image\npatches, we do not claim that the overall pipeline of\n\ufb02attening + matrix multiply constitutes a state-of-the-\nart convolution method\u2014we only claim that using our\nmethod in this pipeline outperforms using other AMM\nmethods there.\nIn short, while we believe that our ideas show great promise\nfor accelerating full neural networks and more layer types,\nmaking this happen requires much more research.\nE.9. Additional Results\nIn Section 5, we showed the classi\ufb01cation accuracy as a\nfunction of wall time for the CIFAR-10 and CIFAR-100\nsoftmax classi\ufb01ers, as well as on the UCR datasets.\nIn\nFigure 8 and Figure 9, we instead show normalized mean\nsquared error versus time. In Figure 10 and Figure 11, we\nshow accuracy or NMSE versus number of operations per-\nformed, where one operation is either one multiply-add or\none table lookup, depending on the method. The \ufb01rst two\n\ufb01gures illustrate that NMSE is closely related to classi\ufb01-\ncation accuracy, but with imperfect NMSE still yielding\nexcellent accuracy in many cases.\nThe second two \ufb01g-\nures show that our method\u2019s superior results are not merely\ncaused by the use of faster CPU instructions, but also by\nthe use of fewer basic operations at the algorithm level.\n", "type": "paragraph", "source": "extract all headings", "confidence": 0.057343777269124985, "timestamp": 1753419110.3155096}
{"response": "Multiplying Matrices Without Multiplying\nE.7. Caltech101\nWe only extracted valid windows\u2014i.e., never past the edge\nof an image. We extracted the windows in CHW order,\nmeaning that scalars from the same color channel were\nplaced at contiguous indices. The \u201c\ufb01rst\u201d images are based\non \ufb01lename in lexicographic order.\nWe used pairs of \ufb01lters because using a single \ufb01lter would\nmean timing a matrix-vector product instead of a matrix-\nmatrix product.\nTo allow meaningful speed comparisons across images, we\nresized and center-cropped each image to 224 \u00d7 224 as\ncommonly done in image classi\ufb01cation pipelines (He et al.,\n2016a;b; Huang et al., 2017). We then extracted sliding\nwindows of the appropriate size and used each (\ufb02attened)\nwindow as one row of \u02dc\nA or A. We similarly \ufb02attened the\n\ufb01lters, with each set of coef\ufb01cients forming one column of\nB. In both cases, B has two columns\u2014this is because us-\ning a single \ufb01lter would mean timing a matrix-vector prod-\nuct instead of a matrix-matrix product. Two columns also\nmade sense since Sobel \ufb01lters are often used in horizon-\ntal and vertical pairings, and Gaussian \ufb01lters are often used\ntogether to perform difference-of-Gaussians transforms.\nEven though the RGB values at each position are naturally\nunsigned 8-bit integers, we allowed all rival methods to\noperate on them as 32-bit \ufb02oating point, without includ-\ning the conversion when timing them.\nBecause it only\nrequires checking whether values are above a threshold,\nMADDNESS can operate on 8-bit data directly.\nE.8. Why Not Speed Up Whole Neural Nets?\nUsing our ideas to accelerate overall neural networks and\nother layer types would be a valuable contribution. In fact,\nwe are actively working on this problem. However, as we\nstate in the introduction and problem statement, our focus\nin this paper is approximate matrix multiplication (AMM)\nand we deliberately make no claim about accelerating en-\ntire neural networks or convolutional layers. We limit our\nscope in this way for several reasons:\n1. Approximate matrix multiplication is an established re-\nsearch problem of general interest independent of deep\nlearning.\n2. Lifting a method from accelerating a single layer to an\noverall network is challenging. Just as scalar quantiza-\ntion of network parameters is simple for a single layer\nbut an active area of research for an entire network, so\ntoo is using our method on multiple layers at once an\nopen research problem.\nFor example, it is not clear\nhow to deal with the fact that distributions of activations\nchange throughout training, or how to ef\ufb01ciently incor-\nporate our non-differentiable hash function. We could\nshow how to accelerate one internal FC layer in a net-\nwork, but we don\u2019t want to risk misleading the reader\u2014it\nwould be unclear what conclusions to draw from such re-\nsults, particularly given the dif\ufb01culty of retraining / \ufb01ne-\ntuning without introducing many lurking variables (c.f.,\n(Blalock et al., 2020)).\n3. It is correct that convolution can be reduced to GEMM\nusing im2col, and that accelerating convolution using\nour ideas would be a valuable contribution. However,\nstate-of-the-art algorithms for convolution exploit struc-\nture that is not available to general matrix multiply algo-\nrithms. To match the performance of specialized Wino-\ngrad, direct, FFT-based, and hybrid convolution schemes\nthat do exploit this additional structure, we would have\nto make modi\ufb01cations to our approach that would make\nit less general. For example, the individual spatial po-\nsitions should be encoded only once, and then reused at\nmultiple \ufb01lter positions. Regarding Section 5.5: while\nwe do test our method on matrices of \ufb02attened image\npatches, we do not claim that the overall pipeline of\n\ufb02attening + matrix multiply constitutes a state-of-the-\nart convolution method\u2014we only claim that using our\nmethod in this pipeline outperforms using other AMM\nmethods there.\nIn short, while we believe that our ideas show great promise\nfor accelerating full neural networks and more layer types,\nmaking this happen requires much more research.\nE.9. Additional Results\nIn Section 5, we showed the classi\ufb01cation accuracy as a\nfunction of wall time for the CIFAR-10 and CIFAR-100\nsoftmax classi\ufb01ers, as well as on the UCR datasets.\nIn\nFigure 8 and Figure 9, we instead show normalized mean\nsquared error versus time. In Figure 10 and Figure 11, we\nshow accuracy or NMSE versus number of operations per-\nformed, where one operation is either one multiply-add or\none table lookup, depending on the method. The \ufb01rst two\n\ufb01gures illustrate that NMSE is closely related to classi\ufb01-\ncation accuracy, but with imperfect NMSE still yielding\nexcellent accuracy in many cases.\nThe second two \ufb01g-\nures show that our method\u2019s superior results are not merely\ncaused by the use of faster CPU instructions, but also by\nthe use of fewer basic operations at the algorithm level.\n", "type": "paragraph", "source": "1 paragraph", "confidence": 0.0624832846224308, "timestamp": 1753419138.8751001}
{"response": "INTRODUCTION", "type": "paragraph", "source": "1 paragraph", "confidence": 0.39227449893951416, "timestamp": 1753420382.3627727}
{"response": "Introduction Design thinking is a problem-solving framework that emphasizes user-centricity, creativity, and iterative testing. Key Principles The five key stages are: Empathize, Define, Ideate, Prototype, and Test. Empathy Mapping Empathy mapping is a collaborative visualization used to articulate what we know about a specific type of user. It externalizes user knowledge to create a shared understanding of user needs. Ideation Strategies Common ideation techniques include brainstorming, brainwriting, and mind mapping. The goal is to generate a wide array of ideas without judgment. Final Thoughts By incorporating design thinking into UX, teams can better align solutions with actual user needs, driving product success.", "type": "paragraph", "source": "1 paragraph", "confidence": 0.10464289784431458, "timestamp": 1753420817.1263845}
{"response": "Introduction Design thinking is a problem-solving framework that emphasizes user-centricity, creativity, and iterative testing. Key Principles The five key stages are: Empathize, Define, Ideate, Prototype, and Test. Empathy Mapping Empathy mapping is a collaborative visualization used to articulate what we know about a specific type of user. It externalizes user knowledge to create a shared understanding of user needs. Ideation Strategies Common ideation techniques include brainstorming, brainwriting, and mind mapping. The goal is to generate a wide array of ideas without judgment. Final Thoughts By incorporating design thinking into UX, teams can better align solutions with actual user needs, driving product success.", "type": "paragraph", "source": "1 paragraph", "confidence": 0.10464289784431458, "timestamp": 1753420860.1130636}
{"response": "This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph", "type": "paragraph", "source": "1 paragraph", "confidence": 0.5578959584236145, "timestamp": 1753421582.9862313}
{"response": "Technical Architecture This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. Voice Interaction Workflow This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. Challenges Faced This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. Future Scope", "type": "paragraph", "source": "1 paragraph", "confidence": 0.4273342490196228, "timestamp": 1753422015.0326662}
{"response": "Adobe Hackathon Voice PDF Assistant Introduction This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. Problem Statement This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. Proposed Solution This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text.", "type": "paragraph", "source": "extract 1 paragraph", "confidence": 0.6243442296981812, "timestamp": 1753422896.1734476}
{"response": "Adobe Hackathon Voice PDF Assistant Introduction This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. Problem Statement This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. Proposed Solution This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text. This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph extraction. The voice assistant should be able to differentiate between headings and normal text.", "type": "paragraph", "source": "extract 1 paragraph", "confidence": 0.6243442296981812, "timestamp": 1753422921.1262844}
{"response": "Introduction  This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph  extraction. The voice assistant should be able to differentiate between headings and normal text.  This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph  extraction. The voice assistant should be able to differentiate between headings and normal text.  This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph  extraction. The voice assistant should be able to differentiate between headings and normal text.  Problem Statement  This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph  extraction. The voice assistant should be able to differentiate between headings and normal text.  This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph  extraction. The voice assistant should be able to differentiate between headings and normal text.  This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph  extraction. The voice assistant should be able to differentiate between headings and normal text.  Proposed Solution  This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph  extraction. The voice assistant should be able to differentiate between headings and normal text.  This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph  extraction. The voice assistant should be able to differentiate between headings and normal text.  This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph  extraction. The voice assistant should be able to differentiate between headings and normal text.", "type": "paragraph", "source": "1 paragraph", "confidence": 0.43719950318336487, "timestamp": 1753424481.4220939}
{"response": "This is a sample paragraph under the heading. It contains multiple lines of text to test paragraph", "type": "paragraph", "source": "1 paragraph", "confidence": 0.5578959584236145, "timestamp": 1753424793.4056783}
